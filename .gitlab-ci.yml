variables:
  KIND_VERSION: "0.19.0"
  PIPELINE_TOOLBOX_TAG: "toolbox-v1"

stages:
  - build
  - test
  - publish

include:
  - project: 'Northern.tech/Mender/mendertesting'
    file: '.gitlab-ci-check-commits-signoffs.yml'
  - project: 'Northern.tech/Mender/mendertesting'
    file: '.gitlab-ci-check-license.yml'
  - project: 'Northern.tech/Mender/mendertesting'
    file: '.gitlab-ci-github-status-updates.yml'

build:pipeline-toolbox-image:
  tags:
    - mender-qa-worker-generic-light
  stage: .pre
  image: docker
  services:
    - docker:dind
  rules:
    - if: '$CI_COMMIT_BRANCH == "MC-6865-helm-upgrade-tests"'
  script:
    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER $CI_REGISTRY --password-stdin
    - |
      docker build \
            --build-arg BUILDKIT_INLINE_CACHE=1 \
            --cache-from ${CI_REGISTRY_IMAGE}:${PIPELINE_TOOLBOX_TAG} \
            -t ${CI_REGISTRY_IMAGE}:${PIPELINE_TOOLBOX_TAG} \
            -f tests/Dockerfile \
            tests/
    - docker push ${CI_REGISTRY_IMAGE}:${PIPELINE_TOOLBOX_TAG}

test:setup_eks_cluster:
  image: ${CI_REGISTRY_IMAGE}:${PIPELINE_TOOLBOX_TAG}
  stage: .pre
  needs: ["build:pipeline-toolbox-image"]
  rules:
    - if: '$CI_COMMIT_BRANCH == "MC-6865-helm-upgrade-tests"'
  before_script:
  script:
    - export AWS_ACCESS_KEY_ID=$CI_EKSCTL_ACCESS_KEY_ID_TEST
    - export AWS_SECRET_ACCESS_KEY=$CI_EKSCTL_AWS_SECRET_ACCESS_KEY_TEST
    - export AWS_DEFAULT_REGION=eu-central-1
    - echo "DEBUG - aws sts get-caller-identity"
    - aws sts get-caller-identity
    - echo "DEBUG - kubectl version - $(kubectl version --client)"
    - echo "DEBUG - eksctl version - $(eksctl version)"
    - echo "DEBUG - helm version - $(helm version)"
    - echo "DEBUG - os version - $(cat /etc/os-release)"
    - echo "DEBUG - this user - $(id)"
    - echo "INFO - eks cluster setup"
    - |
      eksctl create cluster \
        -n helmtesting-${CI_PIPELINE_ID} \
        --tags "env=helmtestingci"
    - echo "DEBUG - kubectl cluster version:"
    - kubectl version

build:
  stage: build
  image: debian:buster
  before_script:
    - apt-get update -y
    - apt-get install -y curl make
    - curl -L https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | DESIRED_VERSION="v3.8.2" bash
  script:
    - make lint
    - make package
  artifacts:
    expire_in: 2w
    paths:
      - mender-*.tgz

.get_kubectl_and_tools: &get_kubectl_and_tools
  # Install kubectl
  - apt update && apt install -yyq curl
  - curl -LO https://storage.googleapis.com/kubernetes-release/release/v1.23.6/bin/linux/amd64/kubectl
  - chmod +x ./kubectl
  - mv ./kubectl /usr/local/bin/kubectl
  # Install AWS CLI and aws-iam-authenticator
  - apt install -yyq awscli
  - curl -o aws-iam-authenticator https://amazon-eks.s3.us-west-2.amazonaws.com/1.15.10/2020-02-22/bin/linux/amd64/aws-iam-authenticator
  - chmod +x ./aws-iam-authenticator
  - mv ./aws-iam-authenticator /usr/local/bin/aws-iam-authenticator
  # Install kubectx
  - apt install -yyq kubectx

.setup_eks_cluster_staging: &setup_eks_cluster_staging
  # Configure AWS CLI for staging cluster
  - export AWS_ACCESS_KEY_ID=$CI_JOBS_AWS_ACCESS_KEY_ID_STAGING
  - export AWS_SECRET_ACCESS_KEY=$CI_JOBS_AWS_SECRET_ACCESS_KEY_STAGING
  - export AWS_DEFAULT_REGION=$CI_JOBS_AWS_REGION_STAGING
  - aws eks --region $CI_JOBS_AWS_REGION_STAGING update-kubeconfig --name $CI_JOBS_AWS_EKS_CLUSTER_NAME_STAGING
  - kubectl config set-context --current --namespace=mender-helm-tests

.setup_s3_helm_chart_repo: &setup_s3_helm_chart_repo
  # Configure AWS CLI for the S3 repository
  - export AWS_ACCESS_KEY_ID=$S3_HELM_CHART_REPO_AWS_ACCESS_KEY_ID
  - export AWS_SECRET_ACCESS_KEY=$S3_HELM_CHART_REPO_AWS_SECRET_ACCESS_KEY
  - export AWS_DEFAULT_REGION=$S3_HELM_CHART_REPO_AWS_REGION
  - export AWS_S3_SSE=AES256

test:helm_chart_install:
  rules:
    - if: '$CI_COMMIT_BRANCH == "master" || $CI_COMMIT_BRANCH == "master-next" || $RUN_HELM_CHART_INSTALL == "true" || $CI_COMMIT_TAG'
  stage: test
  dependencies:
    - build
  image: debian:buster
  before_script:
    - *get_kubectl_and_tools
    - *setup_eks_cluster_staging
    # Install test dependencies
    - apt install -yyq make uuid-runtime
    - tests/ci-deps-k8s.sh
    # Clean possible leftovers from an unfinished run
    - tests/ci-test-teardown.sh || true
    - tests/ci-make-clean.sh || true
  script:
    - tests/ci-make-deps.sh
    - tests/ci-make-helm.sh
    - make test
  after_script:
    - *setup_eks_cluster_staging
    - tests/ci-make-clean.sh

test:wip_helm_chart_install:
  image: ${CI_REGISTRY_IMAGE}:${PIPELINE_TOOLBOX_TAG}
  stage: test
  needs: ["test:setup_eks_cluster"]
  dependencies:
    - test:setup_eks_cluster
  rules:
    - if: '$CI_COMMIT_BRANCH == "MC-6865-helm-upgrade-tests"'
  before_script:
    - export AWS_ACCESS_KEY_ID=$CI_EKSCTL_ACCESS_KEY_ID_TEST
    - export AWS_SECRET_ACCESS_KEY=$CI_EKSCTL_AWS_SECRET_ACCESS_KEY_TEST
    - export AWS_DEFAULT_REGION=eu-central-1
  script:
    - echo "DEBUG - kubectl version - $(kubectl version --client)"
    - echo "DEBUG - eksctl version - $(eksctl version)"
    - echo "DEBUG - helm version - $(helm version)"
    - echo "DEBUG - os version - $(cat /etc/os-release)"
    - echo "DEBUG - this user - $(id)"
    - echo "DEBUG - kubeconfig file:"
    - eksctl utils write-kubeconfig --cluster=helmtesting-${CI_PIPELINE_ID}
    - echo "DEBUG - get kubectl nodes"
    - kubectl config current-context
    - kubectl get nodes
    - echo "INFO - installing helm from scratch"
    - |
      helm upgrade -i \
        --debug \
        mender-latest \
        -f mender/values.yaml \
        -f tests/keys.yaml \
        -f tests/values.yaml \
        --set global.image.username=${REGISTRY_MENDER_IO_USERNAME} \
        --set global.image.password="${REGISTRY_MENDER_IO_PASSWORD}" \
        --set global.s3.AWS_ACCESS_KEY_ID="${MINIO_accessKey}" \
        --set global.s3.AWS_SECRET_ACCESS_KEY="${MINIO_secretKey}" ./mender
  after_script:
    - echo "DEBUG - cleanup"

publish:helm_chart_publishing:
  rules:
    - if: '$CI_COMMIT_TAG'
      changes:
        - mender/Chart.yaml
      when: manual
  stage: publish
  dependencies:
    - build
  image: debian:buster
  before_script:
    - apt-get update -y
    - apt-get install -y curl make git
    - curl -L https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | DESIRED_VERSION="v3.8.2" bash
    - *get_kubectl_and_tools
    - helm plugin install https://github.com/hypnoglow/helm-s3.git --version 0.14.0
    - *setup_s3_helm_chart_repo
  script:
    - helm repo add mender s3://${S3_HELM_CHART_REPO}
    - helm s3 push --acl="public-read" --relative --timeout=60s ./mender-*.tgz mender
    - aws cloudfront create-invalidation --distribution-id ${S3_HELM_CHART_CDN_DISTRIBUTION_ID} --paths "/*"

.eks_cleanup: &eks_cleanup
  image: ${CI_REGISTRY_IMAGE}:${PIPELINE_TOOLBOX_TAG}
  stage: .post
  rules:
    - if: '$CI_COMMIT_BRANCH == "MC-6865-helm-upgrade-tests"'
  before_script:
    - export AWS_ACCESS_KEY_ID=$CI_EKSCTL_ACCESS_KEY_ID_TEST
    - export AWS_SECRET_ACCESS_KEY=$CI_EKSCTL_AWS_SECRET_ACCESS_KEY_TEST
    - export AWS_DEFAULT_REGION=eu-central-1
  script:
    - eksctl delete cluster -n helmtesting-${CI_PIPELINE_ID}

cleanup_eks_cluster:failed:
  when: on_failure
  <<: *eks_cleanup

cleanup_eks_cluster:success:
  when: on_success
  <<: *eks_cleanup
